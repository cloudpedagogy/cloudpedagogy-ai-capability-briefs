# AI Capability for Clinical Educators

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

A practical briefing aligned to the CloudPedagogy AI Capability Framework (2026 Edition)

---

## 1. What this brief is for

This brief is for clinical educators responsible for teaching, supervising, and assessing learners in health and care contexts where artificial intelligence increasingly supports diagnosis support, documentation, simulation, feedback, and decision-making.

It is intended for educators involved in:

- undergraduate and postgraduate clinical education
- workplace-based learning and supervision
- assessment of clinical competence and judgement
- simulation, case-based learning, and skills training
- professional standards and patient safety education

This is not a guide to clinical AI tools or decision-support systems.  
It is a capability briefing to support patient safety, educational integrity, and professional judgement when AI becomes part of clinical learning environments.

---

## 2. Why AI capability matters in clinical education

Clinical education sits at the intersection of:

- learning and patient safety
- supervision and accountability
- professional identity formation

AI is increasingly present in clinical contexts through:

- clinical decision-support systems
- documentation and summarisation tools
- simulated cases and training environments
- performance analytics and feedback systems

If clinical education does not explicitly address AI capability:

- learners may defer judgement prematurely
- supervision signals may become blurred
- assessment may no longer reflect independent clinical reasoning
- patient safety risks may be indirectly amplified

AI capability ensures that AI supports learning and safety, rather than shortcutting professional development.

---

## 3. Common risks and blind spots for clinical educators

Across clinical education settings, recurring challenges emerge:

- **Automation bias in learning:** learners over-trusting AI-supported recommendations.
- **Masking of competence gaps:** polished outputs hiding weak clinical reasoning.
- **Assessment misalignment:** assessments not distinguishing judgement from assistance.
- **Supervisory uncertainty:** unclear expectations about acceptable AI use.
- **Ethical lag:** AI use not addressed explicitly in teaching or supervision.
- **Safety drift:** informal AI practices normalised without review.

These risks arise when AI is present but pedagogically unexamined.

---

## 4. Applying the six domains of AI capability in clinical education

The AI Capability Framework provides a structured way to integrate AI into clinical education responsibly.

### 4.1 AI Awareness & Orientation

Clinical educators need a realistic understanding of how AI behaves in clinical contexts.

This includes:

- recognising uncertainty and limitations in AI-supported recommendations
- understanding risks of bias and overconfidence
- avoiding assumptions that AI outputs equate to best clinical practice

This domain supports safe clinical reasoning, not tool endorsement.

---

### 4.2 Humanâ€“AI Co-Agency

Clinical accountability must remain human-led.

AI capability here involves:

- reinforcing that clinical judgement cannot be delegated to systems
- teaching learners when AI may inform and when it must not decide
- modelling appropriate scepticism and verification

Clear co-agency protects patient safety and professional responsibility.

---

### 4.3 Applied Practice & Innovation

AI can support learning when used deliberately.

This domain supports:

- using AI to explore alternative diagnoses or plans as learning prompts
- integrating AI into simulation for reflective discussion
- supporting documentation practice without replacing reasoning

Innovation is appropriate when AI is used as a learning catalyst, not a crutch.

---

### 4.4 Ethics, Equity & Impact

Clinical education carries ethical responsibility.

AI capability in this domain includes:

- recognising how bias in data may affect patient groups
- addressing consent, transparency, and trust
- considering how AI use shapes professional values and attitudes

Ethical education ensures learners understand both benefits and harms.

---

### 4.5 Decision-Making & Governance

Clinical education operates within regulated environments.

AI capability here involves:

- aligning teaching and assessment with professional standards
- documenting expectations about AI use in clinical learning
- ensuring defensible practice in assessment and progression decisions

Good governance supports credibility with regulators and the public.

---

### 4.6 Reflection, Learning & Renewal

Clinical practice and education evolve continuously.

Capability is strengthened when educators:

- review how AI affects learning outcomes and supervision
- update curricula deliberately as technologies change
- support reflective practice around AI-supported care

This domain supports adaptive, safety-focused education.

---

## 5. Practical actions for clinical educators

The following actions strengthen AI capability in clinical education:

- **Make AI part of the curriculum conversation**  
  Discuss AI explicitly in teaching and supervision.

- **Protect clinical reasoning**  
  Design learning and assessment to surface judgement.

- **Clarify expectations**  
  Be explicit about acceptable and unacceptable AI use.

- **Use AI reflectively**  
  Treat AI outputs as discussion prompts, not answers.

- **Align with standards**  
  Ensure practice reflects professional and regulatory guidance.

- **Review and adapt**  
  Reflect on how AI use affects learner development and safety.

---

## 6. Signals of mature AI capability in clinical education

Clinical education environments with strong AI capability typically demonstrate:

- clear expectations around AI use
- explicit teaching of judgement and uncertainty
- assessments aligned to independent reasoning
- confident supervision conversations
- attention to ethics and patient impact
- continuous review of educational practice

These signals reflect educational and clinical maturity, not technological sophistication.

---

## 7. How this brief fits within the AI Capability Framework

This brief applies the AI Capability Framework (2026 Edition) to clinical education and supervision.

To deepen this work, clinical educators may explore:

- the full AI Capability Framework (PDF)
- Practice Guides focused on high-risk and public-impact contexts
- the Application Handbook for curriculum and governance pathways
- scenario-based workshops for clinical education teams

The Framework provides structure.  
Clinical educators provide professional judgement, safety, and learning stewardship.

---

## About CloudPedagogy

CloudPedagogy develops practical, ethical, and future-ready AI capability across education, research, and public service.

This brief is part of the **AI Capability Briefs** series, supporting role-specific judgement and decision-making using the CloudPedagogy AI Capability Framework (2026 Edition).

Learn more about the Framework:  
https://www.cloudpedagogy.com/pages/ai-capability-framework
