# AI Capability for Quality Assurance & Accreditation Teams

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

A practical briefing aligned to the CloudPedagogy AI Capability Framework (2026 Edition)

---

## 1. What this brief is for

This brief is for Quality Assurance (QA) and Accreditation teams responsible for maintaining academic standards, regulatory compliance, and institutional credibility in contexts where artificial intelligence increasingly shapes teaching, assessment, research, and decision-making.

It is intended for teams involved in:

- internal quality assurance and enhancement  
- programme approval and periodic review  
- external accreditation and regulatory engagement  
- audit, validation, and quality reporting  

This is not a compliance checklist or a regulatory interpretation guide.  
It is a capability briefing designed to support proportionate, future-ready QA practice when AI becomes part of everyday academic and professional work.

---

## 2. Why AI capability matters for QA and accreditation

AI has altered how work is produced, reviewed, and evaluated across institutions. As a result:

- traditional indicators of quality and integrity are shifting  
- assessment design, feedback, and evidence require reinterpretation  
- policy and practice may diverge under pressure  
- external scrutiny increasingly asks how AI is governed, not just whether it is allowed  

For QA and accreditation teams, the challenge is to ensure that quality assurance remains credible, consistent, and defensible, without freezing innovation or relying on outdated assumptions.

AI capability enables QA teams to move from reactive compliance toward capability-informed assurance.

---

## 3. Common risks and blind spots for QA and accreditation teams

Across institutions, recurring challenges appear:

- **Policy–practice gaps:** institutional guidance not reflected in programme delivery  
- **Evidence mismatch:** legacy QA evidence no longer indicating learning or integrity  
- **Over-standardisation:** rigid controls that suppress legitimate innovation  
- **Under-scrutiny:** insufficient attention to AI-related risk accumulation  
- **Inconsistent messaging:** conflicting expectations across faculties or programmes  
- **Audit theatre:** performative compliance without meaningful assurance  

These risks arise when QA processes do not evolve alongside practice.

---

## 4. Applying the six domains of AI capability in QA and accreditation

The AI Capability Framework provides QA teams with a structured lens for updating assurance practice responsibly.

### 4.1 AI Awareness & Orientation

QA teams need a shared understanding of how AI affects quality indicators.

This includes:

- recognising where AI alters assessment validity  
- understanding limitations of artefact-based evidence  
- avoiding assumptions that AI risk is uniform across contexts  

This domain supports informed scrutiny, not technical inspection.

---

### 4.2 Human–AI Co-Agency

Quality assurance depends on clear accountability.

AI capability here involves:

- confirming that responsibility for academic judgement remains human-led  
- ensuring AI does not obscure ownership of decisions  
- supporting clarity about who is accountable at each level  

Clear co-agency strengthens auditability and trust.

---

### 4.3 Applied Practice & Innovation

QA must accommodate responsible innovation.

This domain supports:

- risk-based review rather than blanket prohibition  
- recognition of well-designed AI-aware practices  
- enabling improvement alongside assurance  

Innovation is sustainable when QA focuses on principles, not prescriptions.

---

### 4.4 Ethics, Equity & Impact

QA teams safeguard fairness and consistency.

AI capability includes:

- scrutinising differential impacts across student groups  
- ensuring accessibility and inclusion are considered  
- recognising cumulative effects of AI across programmes  

Ethical QA ensures quality is equitable, not merely compliant.

---

### 4.5 Decision-Making & Governance

QA is a governance function.

AI capability here involves:

- ensuring AI-related decisions are documented and explainable  
- aligning QA processes with institutional and external expectations  
- maintaining clear audit trails without excessive bureaucracy  

Good governance supports confidence in internal and external review.

---

### 4.6 Reflection, Learning & Renewal

Quality assurance must evolve continuously.

This domain is strengthened when QA teams:

- review how AI-aware practices perform over time  
- update review criteria iteratively  
- learn from internal and external feedback  

This ensures QA remains credible and future-ready.

---

## 5. Practical actions for QA and accreditation teams

The following actions strengthen AI capability in QA contexts:

- **Update review questions**  
  Ensure QA processes explicitly address AI-related considerations.

- **Focus on decision points**  
  Examine where AI meaningfully influences outcomes.

- **Review evidence expectations**  
  Adapt what counts as valid evidence of quality and integrity.

- **Promote coherence**  
  Identify and address fragmentation across programmes or faculties.

- **Document rationale clearly**  
  Record how AI considerations informed QA judgements.

- **Engage constructively with innovation**  
  Support improvement rather than compliance theatre.

---

## 6. Signals of mature AI capability in QA and accreditation

Institutions with strong AI capability in QA typically demonstrate:

- alignment between policy, practice, and evidence  
- proportionate, risk-based review processes  
- confidence in external accreditation and audit  
- transparent handling of AI-related issues  
- consistent expectations across the institution  
- continuous improvement rather than reactive compliance  

These signals reflect assurance maturity, not rigidity.

---

## 7. How this brief fits within the AI Capability Framework

This brief applies the AI Capability Framework (2026 Edition) to quality assurance and accreditation work.

To deepen this approach, QA teams may explore:

- the full AI Capability Framework (PDF)  
- Practice Guides related to governance and decision-making  
- the Application Handbook for QA integration pathways  
- facilitated QA review or capability workshops  

The Framework provides structure.  
QA and accreditation teams provide institutional assurance and credibility.

---

## About CloudPedagogy

CloudPedagogy develops practical, ethical, and future-ready AI capability across education, research, and public service.

This brief is part of the **AI Capability Briefs** series, supporting role-specific judgement and decision-making using the CloudPedagogy AI Capability Framework (2026 Edition).

Learn more about the Framework:  
https://www.cloudpedagogy.com/pages/ai-capability-framework
