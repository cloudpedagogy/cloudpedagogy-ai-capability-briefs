# AI Capability for Academic Integrity & Misconduct Panels

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

A practical briefing aligned to the CloudPedagogy AI Capability Framework (2026 Edition)

---

## 1. What this brief is for

This brief is for members of Academic Integrity Committees, Misconduct Panels, Appeals Boards, and related decision-making bodies responsible for evaluating alleged breaches of academic integrity in contexts where artificial intelligence increasingly shapes student work.

It is intended for panel members who:

- review suspected misconduct cases  
- interpret evidence related to AI-assisted work  
- make high-stakes decisions affecting student progression  
- operate within institutional policy and regulatory frameworks  

This is not a legal guide, a detection manual, or a policy rewrite.  
It is a capability briefing to support fair judgement, procedural integrity, and defensible decision-making when AI complicates traditional notions of authorship, originality, and intent.

---

## 2. Why AI capability matters for integrity and misconduct panels

AI challenges long-standing assumptions underpinning academic misconduct processes, including:

- how authorship is identified  
- how originality is evidenced  
- how intent is inferred  
- how responsibility is attributed  

Panels are increasingly asked to adjudicate cases where:

- AI use is ambiguous rather than clearly prohibited  
- evidence is probabilistic or indirect  
- student understanding and guidance vary widely  
- institutional expectations are still evolving  

Without explicit AI capability, integrity processes risk becoming inconsistent, inequitable, or legally fragile.

AI capability enables panels to focus on judgement, fairness, and proportionality rather than technological guesswork.

---

## 3. Common risks and blind spots in AI-related misconduct cases

Across institutions, recurring challenges appear:

- **Over-reliance on detection tools:** treating probabilistic indicators as proof  
- **Assumption of intent:** conflating tool use with misconduct  
- **Inconsistent thresholds:** uneven decisions across cases or panels  
- **Policy lag:** applying pre-AI rules to AI-shaped practice  
- **Equity impacts:** disadvantaging students with less guidance or support  
- **Procedural drift:** shifting standards without formal review  

These risks undermine trust in integrity systems if left unaddressed.

---

## 4. Applying the six domains of AI capability in integrity decision-making

The AI Capability Framework provides a principled lens for adjudicating AI-related cases fairly and consistently.

### 4.1 AI Awareness & Orientation

Panel members need a realistic understanding of what AI detection can and cannot show.

This includes:

- recognising the probabilistic nature of AI detection tools  
- understanding common false positives and limitations  
- avoiding assumptions that AI use is inherently deceptive  

This domain supports informed interpretation, not technical certainty.

---

### 4.2 Humanâ€“AI Co-Agency

Integrity decisions must remain human-led.

AI capability here involves:

- ensuring AI tools inform, but do not determine, outcomes  
- retaining responsibility for interpretation and judgement  
- resisting pressure to outsource decisions to technology  

Clear co-agency protects due process and institutional credibility.

---

### 4.3 Applied Practice & Innovation

Panels must adapt practice as assessment and learning evolve.

This domain supports:

- updating interpretive approaches without rewriting policy ad hoc  
- recognising legitimate educational uses of AI  
- distinguishing poor learning design from misconduct  

Innovation here is procedural, not technological.

---

### 4.4 Ethics, Equity & Impact

Integrity decisions have significant personal and institutional consequences.

AI capability in this domain includes:

- considering differential access to AI guidance and support  
- recognising how bias may enter detection and interpretation  
- ensuring proportional responses to ambiguous practice  

Ethical adjudication requires sensitivity to power and context.

---

### 4.5 Decision-Making & Governance

Misconduct panels operate within governance and regulatory constraints.

AI capability here involves:

- documenting rationale clearly in AI-related cases  
- aligning decisions with published policy and precedent  
- supporting defensible outcomes under appeal or review  

Good governance ensures consistency, transparency, and trust.

---

### 4.6 Reflection, Learning & Renewal

Integrity processes must evolve alongside educational practice.

Capability is strengthened when panels:

- review patterns in AI-related cases  
- identify policy or design gaps exposed by cases  
- feed learning back into institutional guidance  

This domain supports systemic improvement rather than reactive enforcement.

---

## 5. Practical actions for integrity and misconduct panels

The following actions strengthen AI capability in integrity processes:

- **Treat detection as signal, not proof**  
  Use AI indicators to prompt enquiry, not determine guilt.

- **Focus on learning intent**  
  Consider what the assessment was designed to evidence.

- **Interrogate guidance clarity**  
  Examine what students were reasonably expected to understand.

- **Document judgement explicitly**  
  Record how evidence was interpreted and weighed.

- **Apply proportionality**  
  Distinguish between misconduct, misunderstanding, and poor design.

- **Feed learning upstream**  
  Share insights with programme and design teams.

---

## 6. Signals of mature AI capability in integrity processes

Institutions with strong AI capability in integrity systems typically demonstrate:

- consistent, explainable decisions  
- reduced reliance on automated detection  
- alignment between policy, assessment design, and adjudication  
- equitable treatment of students  
- confidence under appeal or external scrutiny  
- learning-oriented integrity cultures  

These signals reflect procedural maturity, not punitive strength.

---

## 7. How this brief fits within the AI Capability Framework

This brief applies the AI Capability Framework (2026 Edition) to academic integrity and misconduct decision-making.

To deepen this work, institutions may explore:

- the full AI Capability Framework (PDF)  
- Practice Guides focused on assessment and governance  
- the Application Handbook for institutional implementation  
- facilitated reviews of integrity policy and practice  

The Framework provides structure.  
Integrity panels provide fairness, judgement, and institutional trust.

---

## About CloudPedagogy

CloudPedagogy develops practical, ethical, and future-ready AI capability across education, research, and public service.

This brief is part of the **AI Capability Briefs** series, supporting role-specific judgement and decision-making using the CloudPedagogy AI Capability Framework (2026 Edition).

Learn more about the Framework:  
https://www.cloudpedagogy.com/pages/ai-capability-framework
