# AI Capability for External Examiners

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

A practical briefing aligned to the CloudPedagogy AI Capability Framework (2026 Edition)

---

## 1. What this brief is for

This brief is for External Examiners responsible for assuring academic standards, fairness, and comparability across programmes and institutions in contexts where artificial intelligence increasingly shapes student work, assessment design, and feedback practices.

It is intended for examiners who:

- review assessment briefs and marking criteria  
- scrutinise samples of student work  
- comment on academic standards and comparability  
- provide independent assurance to institutions and regulators  

This is not guidance on detecting AI use or enforcing policy.  
It is a capability briefing to support informed judgement, proportionate scrutiny, and defensible reporting when AI is part of contemporary assessment practice.

---

## 2. Why AI capability matters for external examining

AI has altered how assessed work is produced and refined, often in ways that are invisible in final submissions.

For External Examiners, this creates new challenges:

- traditional signals of authorship and effort are less reliable  
- assessment tasks may no longer test what they were designed to test  
- practices vary widely across modules and programmes  
- students may receive inconsistent guidance about acceptable AI use  

AI capability enables External Examiners to focus on standards, validity, and coherence, rather than attempting to infer tool use from artefacts alone.

---

## 3. Common risks and blind spots for External Examiners

Across institutions, recurring issues arise:

- **Artefact-focused scrutiny:** concentrating on student outputs without examining task design  
- **Detection assumptions:** expecting institutions to prove AI use or non-use  
- **Inconsistent benchmarks:** difficulty comparing standards when AI guidance varies  
- **Policy overreach:** conflating local guidance with national or sector norms  
- **Equity blind spots:** overlooking uneven student access to guidance and support  
- **Role drift:** being drawn into operational decisions rather than independent assurance  

These risks stem from applying legacy examining assumptions to a changed assessment context.

---

## 4. Applying the six domains of AI capability in external examining

The AI Capability Framework provides a structured lens for modernising external examining practice.

### 4.1 AI Awareness & Orientation

External Examiners need a realistic understanding of how AI affects assessment performance.

This includes:

- recognising that polished work may not reflect independent thinking  
- understanding common limitations of AI-generated content  
- avoiding assumptions that AI use can be reliably inferred post hoc  

This domain supports context-aware scrutiny, not technical investigation.

---

### 4.2 Humanâ€“AI Co-Agency

Accountability for academic judgement must remain human-led.

For External Examiners, this involves:

- assessing whether assessments require student reasoning and judgement  
- checking that expectations about AI use are explicit and fair  
- reinforcing that responsibility for standards sits with programme design  

Clear co-agency refocuses scrutiny on educational intent.

---

### 4.3 Applied Practice & Innovation

Assessment innovation is inevitable.

AI capability enables External Examiners to:

- recognise legitimate AI-aware assessment design  
- distinguish innovation from erosion of standards  
- support evolution in assessment practice where defensible  

This domain helps examiners act as critical friends, not gatekeepers.

---

### 4.4 Ethics, Equity & Impact

External Examiners play a role in safeguarding fairness.

This includes:

- scrutinising whether AI-related guidance disadvantages certain students  
- considering cumulative equity impacts across programmes  
- recognising how unclear expectations affect student confidence and outcomes  

Ethical assurance requires attention to systemic effects, not isolated cases.

---

### 4.5 Decision-Making & Governance

External examining is part of formal governance.

AI capability here involves:

- evaluating whether assessment decisions are traceable and defensible  
- checking alignment between policy, guidance, and practice  
- framing feedback that supports improvement rather than compliance theatre  

Good governance supports confidence in external assurance processes.

---

### 4.6 Reflection, Learning & Renewal

External examining practice must adapt.

Capability is strengthened when examiners:

- reflect on how AI is changing assessment norms  
- update assumptions about evidence and assurance  
- share learning across examining roles and institutions  

This domain ensures external examining remains credible and relevant.

---

## 5. Practical actions for External Examiners

The following actions support AI-aware external examining:

- **Scrutinise assessment design**  
  Focus on whether tasks still measure intended learning outcomes.

- **Check clarity of guidance**  
  Look for explicit, consistent expectations about AI use.

- **Assess coherence across modules**  
  Identify fragmentation or conflicting approaches within programmes.

- **Avoid artefact-only conclusions**  
  Treat outputs as insufficient evidence on their own.

- **Frame constructive feedback**  
  Support institutions in strengthening design and communication.

- **Document judgement clearly**  
  Make the basis of assurance transparent in reports.

---

## 6. Signals of mature AI capability from an external examiner perspective

Programmes demonstrating strong AI capability typically show:

- coherent assessment design aligned to learning outcomes  
- clear, consistent guidance for students  
- reduced reliance on detection narratives  
- confidence in discussing AI-related practice  
- defensible responses to external scrutiny  
- reflective improvement over time  

These signals indicate academic assurance maturity, not technological control.

---

## 7. How this brief fits within the AI Capability Framework

This brief applies the AI Capability Framework (2026 Edition) to the independent assurance role of External Examiners.

To deepen this approach, examiners may explore:

- the full AI Capability Framework (PDF)  
- Practice Guides focused on teaching, assessment, and governance  
- the Application Handbook for interpretive guidance  
- sector discussions on evolving assessment assurance  

The Framework provides structure.  
External Examiners provide independent judgement and assurance.

---

## About CloudPedagogy

CloudPedagogy develops practical, ethical, and future-ready AI capability across education, research, and public service.

This brief is part of the **AI Capability Briefs** series, supporting role-specific judgement and decision-making using the CloudPedagogy AI Capability Framework (2026 Edition).

Learn more about the Framework:  
https://www.cloudpedagogy.com/pages/ai-capability-framework
