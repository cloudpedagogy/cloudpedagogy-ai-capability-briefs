# AI Capability for Assessment Leads

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

A practical briefing aligned to the CloudPedagogy AI Capability Framework (2026 Edition)

---

## 1. What this brief is for

This brief is for Assessment Leads with responsibility for assessment strategy, integrity, coherence, and quality across programmes or faculties in contexts where artificial intelligence is now embedded in how students plan, produce, and refine assessed work.

It is intended for:

- assessment leads and chairs
- programme-level assessment coordinators
- academic quality and standards leads
- staff responsible for assessment policy and design oversight

This is not guidance on detection tools or misconduct procedures.  
It is a capability briefing designed to support confident, defensible assessment leadership in an AI-rich educational environment.

---

## 2. Why AI capability matters in assessment leadership

AI has changed how students:

- draft and revise written work
- structure arguments and analyses
- generate examples or explanations
- receive feedback outside formal teaching

As a result, assessment risk has shifted:

- from isolated misconduct to systemic design issues
- from individual behaviour to programme-level coherence
- from rule enforcement to judgement about what assessment is for

For Assessment Leads, AI capability is essential to ensure that assessment remains valid, fair, and meaningful, rather than reactive or punitive.

---

## 3. Common risks and blind spots for Assessment Leads

Across institutions, recurring assessment challenges emerge:

- **Validity erosion:** tasks no longer measure intended learning outcomes.
- **Inconsistent expectations:** different modules applying conflicting assumptions about AI use.
- **Over-reliance on detection:** treating technical tools as substitutes for design judgement.
- **Policy–practice gaps:** institutional guidance not reflected in real assessment design.
- **Equity risks:** uneven impacts on students with differing access or confidence.
- **Assessment overload:** frequent redesign without shared principles or coordination.

These risks cannot be resolved through enforcement alone.  
They require capability-led assessment leadership.

---

## 4. Applying the six domains of AI capability to assessment leadership

The AI Capability Framework supports Assessment Leads in evolving assessment strategy with clarity and coherence.

### 4.1 AI Awareness & Orientation

Assessment Leads need a clear understanding of how AI affects assessment performance.

This includes:

- recognising where AI support meaningfully alters task completion
- understanding limitations of AI-generated outputs
- avoiding assumptions that AI use is uniform across students

This domain informs assessment judgement, not technical control.

---

### 4.2 Human–AI Co-Agency

Assessment design defines responsibility.

For Assessment Leads, this means:

- clarifying where student judgement must remain central
- ensuring assessments require reasoning, evaluation, and reflection
- avoiding designs that reward uncritical AI substitution

Explicit co-agency protects assessment integrity.

---

### 4.3 Applied Practice & Innovation

AI capability enables assessment innovation rather than stasis.

This includes:

- supporting diverse assessment formats aligned to learning outcomes
- enabling safe experimentation with AI-aware assessment designs
- sharing effective practices across programmes

Innovation becomes sustainable when it is strategically guided, not ad hoc.

---

### 4.4 Ethics, Equity & Impact

Assessment decisions shape fairness and student trust.

Assessment Leads should consider:

- differential impacts on student groups
- accessibility and support implications
- cumulative effects across programmes

Ethical assessment leadership requires anticipatory judgement, not retrospective fixes.

---

### 4.5 Decision-Making & Governance

Assessment is a core governance function.

AI capability in this domain involves:

- documenting how AI considerations inform assessment strategy
- aligning assessment practice with institutional policy
- ensuring defensibility to examiners, regulators, and reviewers

Good governance focuses on traceable reasoning, not blanket rules.

---

### 4.6 Reflection, Learning & Renewal

Assessment practice must evolve.

Assessment Leads strengthen this domain by:

- reviewing how AI-aware assessments perform in practice
- supporting reflective dialogue among teaching teams
- updating strategy as expectations and contexts shift

This ensures assessment remains robust and credible over time.

---

## 5. Practical actions for Assessment Leads

The following actions support effective AI-aware assessment leadership:

- **Audit assessment validity**  
  Identify where AI use undermines or reshapes outcome measurement.

- **Establish shared assessment principles**  
  Provide programme-level guidance rather than module-by-module fixes.

- **Support staff capability**  
  Facilitate structured conversations about assessment design and judgement.

- **Reduce over-reliance on detection**  
  Prioritise assessment redesign over surveillance.

- **Document assessment decisions**  
  Maintain clear records of AI-related design choices.

- **Communicate clearly with students**  
  Ensure expectations around assessment and AI use are explicit and consistent.

---

## 6. Signals of mature AI capability in assessment leadership

Assessment systems with strong AI capability typically demonstrate:

- clear alignment between learning outcomes and assessment tasks
- consistent expectations across modules and programmes
- assessments that foreground human judgement
- reduced misconduct-driven redesign cycles
- confidence in quality assurance and external review
- transparent communication with students

These signals reflect assessment maturity, not restriction.

---

## 7. How this brief fits within the AI Capability Framework

This brief applies the AI Capability Framework (2026 Edition) to assessment leadership and oversight.

To deepen this work, Assessment Leads may explore:

- the full AI Capability Framework (PDF)
- the Application Handbook for assessment design pathways
- Practice Guides focused on teaching, assessment, and governance
- facilitated assessment review or redesign workshops

The Framework provides structure.  
Assessment leadership provides academic judgement and assurance.

---

## About CloudPedagogy

CloudPedagogy develops practical, ethical, and future-ready AI capability across education, research, and public service.

This brief is part of the **AI Capability Briefs** series, supporting role-specific judgement and decision-making using the CloudPedagogy AI Capability Framework (2026 Edition).

Learn more about the Framework:  
https://www.cloudpedagogy.com/pages/ai-capability-framework
