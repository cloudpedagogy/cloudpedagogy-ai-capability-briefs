# AI Capability for Research Managers & Portfolio Leads

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

A practical briefing aligned to the CloudPedagogy AI Capability Framework (2026 Edition)

---

## 1. What this brief is for

This brief is for Research Managers, Research Development Managers, Portfolio Leads, and senior professional staff responsible for coordinating, overseeing, and assuring research activity across projects, programmes, or portfolios in contexts where artificial intelligence increasingly shapes research practice.

It is intended for roles that:

- support multiple research teams or units  
- oversee pre-award and post-award activity  
- advise on compliance, reporting, and strategy  
- influence institutional research priorities and capacity  

This is not a technical guide to AI tools or research methods.  
It is a capability briefing to support confident judgement, role clarity, and defensible decision-making when AI becomes part of everyday research workflows.

---

## 2. Why AI capability matters for research managers and portfolio leads

Research managers operate at critical coordination points in the research system. They are often responsible for:

- interpreting funder expectations  
- advising researchers on acceptable practice  
- monitoring delivery, reporting, and risk  
- identifying trends across projects and disciplines  

As AI becomes embedded in research activity, research managers are increasingly asked to:

- advise on AI use without being disciplinary experts  
- balance innovation with compliance and reputational risk  
- manage inconsistency across teams and faculties  
- respond to funder or audit scrutiny  

Without explicit AI capability, research management risks becoming reactive, uneven, or overly cautious.

AI capability enables research managers to act as *trusted enablers* rather than informal gatekeepers or risk absorbers.

---

## 3. Common risks and blind spots in AI-influenced research management

Across institutions, recurring challenges appear:

- **Invisible AI use:** AI shaping research activity without disclosure  
- **Inconsistent advice:** different messages given across units or teams  
- **Role overload:** responsibility assumed without decision authority  
- **Funder uncertainty:** unclear expectations around AI use in bids or reports  
- **Portfolio blind spots:** cumulative AI-related risk not visible at project level  
- **Compliance creep:** adding controls without improving assurance  

These risks arise from capability gaps, not lack of professionalism.

---

## 4. Applying the six domains of AI capability in research management

The AI Capability Framework provides a shared lens for managing AI-related research issues consistently and proportionately.

### 4.1 AI Awareness & Orientation

Research managers need a practical understanding of how AI affects research workflows.

This includes:

- recognising common points where AI supports drafting, synthesis, or analysis  
- understanding limitations of AI-generated content  
- avoiding assumptions that AI use is uniform across disciplines  

This domain supports informed advising, not technical assessment.

---

### 4.2 Humanâ€“AI Co-Agency

Accountability for research decisions must remain human-led.

AI capability here involves:

- reinforcing that researchers retain responsibility for intellectual content  
- avoiding narratives that shift accountability to tools  
- clarifying advisory versus decision-making boundaries  

Clear co-agency protects both research teams and management roles.

---

### 4.3 Applied Practice & Innovation

AI can support efficiency and innovation when used deliberately.

This domain enables research managers to:

- support responsible experimentation within clear principles  
- distinguish acceptable assistance from problematic substitution  
- share effective practice across portfolios  

Innovation is sustainable when it is coordinated, not fragmented.

---

### 4.4 Ethics, Equity & Impact

Research management decisions shape opportunity and risk distribution.

AI capability in this domain includes:

- recognising uneven access to AI tools and guidance  
- ensuring advice does not disadvantage particular groups  
- considering reputational and ethical implications at portfolio level  

Ethical oversight requires a system-wide view, not case-by-case reaction.

---

### 4.5 Decision-Making & Governance

Research managers operate close to governance boundaries.

AI capability here involves:

- aligning advice with institutional policy and funder requirements  
- supporting documentation of AI-related decisions  
- knowing when and how to escalate issues to governance bodies  

Good governance supports confidence under scrutiny.

---

### 4.6 Reflection, Learning & Renewal

Research portfolios evolve continuously.

Capability is strengthened when research managers:

- track emerging patterns in AI-related queries or issues  
- share learning across teams and faculties  
- update guidance as norms and funder expectations change  

This domain supports adaptive, future-ready research management.

---

## 5. Practical actions for research managers and portfolio leads

The following actions strengthen AI capability in research management roles:

- **Make AI use discussable**  
  Encourage open conversation with research teams.

- **Align advisory messages**  
  Reduce inconsistency through shared principles and language.

- **Monitor patterns, not incidents**  
  Look for portfolio-level trends rather than isolated cases.

- **Clarify responsibility boundaries**  
  Be explicit about what managers advise on versus decide.

- **Document advisory rationale**  
  Keep brief records where AI considerations shape guidance.

- **Feed learning into policy**  
  Support institutional refinement based on practice.

---

## 6. Signals of mature AI capability in research management

Research environments with strong AI capability at management level typically demonstrate:

- consistent, confident advisory practice  
- alignment with funder and institutional expectations  
- reduced escalation driven by uncertainty  
- transparent handling of AI-related issues  
- trust from research teams and leadership  
- learning-oriented portfolio oversight  

These signals reflect assurance maturity, not restriction.

---

## 7. How this brief fits within the AI Capability Framework

This brief applies the AI Capability Framework (2026 Edition) to research management and portfolio oversight roles.

To deepen this work, research managers may explore:

- the full AI Capability Framework (PDF)  
- Practice Guides focused on research and governance  
- the Application Handbook for structured implementation  
- cross-functional capability workshops  

The Framework provides structure.  
Research managers provide coherence, judgement, and enablement.

---

## About CloudPedagogy

CloudPedagogy develops practical, ethical, and future-ready AI capability across education, research, and public service.

This brief is part of the **AI Capability Briefs** series, supporting role-specific judgement and decision-making using the CloudPedagogy AI Capability Framework (2026 Edition).

Learn more about the Framework:  
https://www.cloudpedagogy.com/pages/ai-capability-framework
