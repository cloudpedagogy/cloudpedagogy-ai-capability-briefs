# AI Capability for Doctoral Supervisors

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

A practical briefing aligned to the CloudPedagogy AI Capability Framework (2026 Edition)

---

## 1. What this brief is for

This brief is for Doctoral Supervisors responsible for guiding doctoral researchers through extended, original research in contexts where artificial intelligence increasingly supports reading, analysis, writing, planning, and reflection.

It is intended for supervisors who:

- oversee research design and intellectual development
- support scholarly writing and argumentation
- advise on ethics, integrity, and authorship
- prepare doctoral researchers for independent academic or professional careers

This is not guidance on policing AI use or prescribing tools.  
It is a capability briefing to support supervisory judgement, intellectual integrity, and developmental mentoring when AI becomes part of doctoral research practice.

---

## 2. Why AI capability matters in doctoral supervision

Doctoral study is fundamentally about:

- developing independent scholarly judgement
- producing original, defensible knowledge
- learning how to navigate uncertainty and complexity

AI tools can support aspects of this journey, but they can also:

- obscure where thinking is happening
- accelerate writing ahead of conceptual clarity
- create uncertainty about authorship and contribution
- distort supervision conversations if unspoken

AI capability enables supervisors to integrate AI thoughtfully into doctoral development, rather than treating it as a threat or ignoring its influence.

---

## 3. Common risks and blind spots for doctoral supervisors

Across disciplines, recurring challenges emerge:

- **Invisible AI use:** doctoral researchers using AI without discussing it.
- **Premature polish:** fluent writing masking conceptual gaps.
- **Dependency risk:** over-reliance on AI for framing or synthesis.
- **Authorship ambiguity:** unclear boundaries of intellectual contribution.
- **Ethics lag:** AI use not reflected in ethics approvals or methods sections.
- **Inconsistent expectations:** different supervisors offering conflicting advice.

These risks arise when AI is outside the supervisory conversation.

---

## 4. Applying the six domains of AI capability in doctoral supervision

The AI Capability Framework provides a shared language for navigating AI within doctoral education.

### 4.1 AI Awareness & Orientation

Supervisors need a realistic understanding of how AI affects doctoral work.

This includes:

- recognising how AI can influence reading, synthesis, and writing
- understanding limitations in AI-generated interpretation
- avoiding assumptions that polished text reflects deep understanding

This domain supports diagnostic supervision, not technical evaluation.

---

### 4.2 Humanâ€“AI Co-Agency

Doctoral research must remain intellectually owned by the candidate.

AI capability here involves:

- reinforcing that judgement, argument, and interpretation are human responsibilities
- helping candidates articulate how AI supports, rather than replaces, thinking
- modelling transparent scholarly practice

Clear co-agency protects originality and academic integrity.

---

### 4.3 Applied Practice & Innovation

AI can support doctoral development when used deliberately.

This domain supports:

- exploratory use of AI to test ideas or perspectives
- reflective comparison between AI outputs and candidate reasoning
- using AI as a prompt for discussion rather than a solution

Innovation is valuable when it strengthens learning, not shortcuts it.

---

### 4.4 Ethics, Equity & Impact

Doctoral researchers operate within ethical frameworks.

AI capability in this domain includes:

- ensuring AI use aligns with ethics approvals and disciplinary norms
- discussing bias, representation, and data sensitivity
- recognising power dynamics and vulnerability in doctoral contexts

Ethical supervision requires proactive conversation, not assumption.

---

### 4.5 Decision-Making & Governance

Doctoral work is subject to formal milestones and examination.

AI capability here involves:

- preparing candidates to explain and justify AI use
- ensuring transparency in methods and acknowledgements
- supporting defensible practice in progression reviews and viva contexts

Good governance supports candidate confidence and examiner trust.

---

### 4.6 Reflection, Learning & Renewal

Doctoral education is developmental over time.

Capability is strengthened when supervisors:

- revisit AI expectations as projects evolve
- reflect on how AI shapes scholarly identity
- adapt supervisory approaches deliberately

This domain supports intellectual independence rather than dependence.

---

## 5. Practical actions for doctoral supervisors

The following actions support AI-aware doctoral supervision:

- **Make AI use discussable**  
  Normalise conversation about how AI is being used.

- **Focus on thinking, not polish**  
  Probe reasoning, decisions, and interpretations explicitly.

- **Clarify boundaries early**  
  Discuss acceptable and unacceptable uses at key stages.

- **Align with ethics and discipline norms**  
  Ensure AI use is reflected appropriately in approvals and methods.

- **Model transparency**  
  Demonstrate how to describe AI use responsibly in scholarly work.

- **Revisit expectations regularly**  
  Treat AI capability as evolving, not fixed.

---

## 6. Signals of mature AI capability in doctoral supervision

Doctoral environments with strong AI capability typically show:

- open, reflective dialogue about AI use
- clear ownership of intellectual contribution
- candidates confident in explaining their methods
- reduced anxiety about integrity or authorship
- alignment between supervision, ethics, and examination
- graduates prepared for AI-rich research environments

These signals reflect scholarly maturity, not restriction.

---

## 7. How this brief fits within the AI Capability Framework

This brief applies the AI Capability Framework (2026 Edition) to doctoral supervision.

To deepen this work, supervisors may explore:

- the full AI Capability Framework (PDF)
- Practice Guides focused on research and high-stakes contexts
- the Application Handbook for reflective supervision pathways
- facilitated discussions within doctoral schools

The Framework provides structure.  
Doctoral Supervisors provide intellectual stewardship and mentorship.

---

## About CloudPedagogy

CloudPedagogy develops practical, ethical, and future-ready AI capability across education, research, and public service.

This brief is part of the **AI Capability Briefs** series, supporting role-specific judgement and decision-making using the CloudPedagogy AI Capability Framework (2026 Edition).

Learn more about the Framework:  
https://www.cloudpedagogy.com/pages/ai-capability-framework
