# AI Capability for Research Support Offices

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0

A practical briefing aligned to the CloudPedagogy AI Capability Framework (2026 Edition)

---

## 1. What this brief is for

This brief is for Research Support Offices (RSOs) and related professional services teams that enable research activity across the full project lifecycle in contexts where artificial intelligence increasingly shapes proposal development, project delivery, reporting, and impact.

It is intended for teams involved in:

- pre-award development and bid support  
- post-award management and reporting  
- research development and coordination  
- impact, engagement, and knowledge exchange  
- institutional liaison with funders and partners  

This is not a guide to grant-writing tools or project management software.  
It is a capability briefing to support confident advisory practice, role clarity, and defensible support when AI becomes part of research workflows.

---

## 2. Why AI capability matters for research support offices

AI is increasingly used — formally and informally — across research activity:

- drafting and refining funding proposals  
- synthesising calls, guidance, and evidence  
- supporting project planning and reporting  
- generating summaries for impact and engagement  

Research Support Offices sit at a critical intersection:

- between researchers and funders  
- between innovation and compliance  
- between aspiration and accountability  

Without AI capability, RSOs risk:

- uncertainty about acceptable AI use in bids and reports  
- inconsistent advice across teams or faculties  
- exposure to funder challenge or reputational risk  
- becoming informal arbiters of AI policy without authority  

AI capability enables RSOs to act as trusted enablers, not bottlenecks or enforcers.

---

## 3. Common risks and blind spots for research support offices

Across institutions, recurring challenges appear:

- **Ambiguous guidance:** unclear expectations about AI use in proposals or reporting  
- **Funder misalignment:** uncertainty about how different funders view AI assistance  
- **Invisible practice:** researchers using AI without discussing it with support teams  
- **Role overload:** RSOs absorbing AI-related risk without decision authority  
- **Inconsistent advice:** differing messages given by different staff or units  
- **Over-proceduralisation:** adding checks that slow work without improving assurance  

These issues arise from capability gaps, not lack of professionalism.

---

## 4. Applying the six domains of AI capability in research support

The AI Capability Framework provides a shared lens for RSOs to support research confidently and consistently.

### 4.1 AI Awareness & Orientation

RSOs need a realistic understanding of how AI affects research development and reporting.

This includes:

- recognising where AI commonly supports drafting and synthesis  
- understanding limitations of AI-generated content  
- avoiding assumptions that AI use is either universal or prohibited  

This domain supports informed advising, not technical evaluation.

---

### 4.2 Human–AI Co-Agency

Responsibility for research content must remain human-owned.

AI capability here involves:

- reinforcing that researchers retain accountability for proposals and reports  
- supporting clarity around acceptable AI assistance  
- avoiding narratives that shift responsibility to tools  

Clear co-agency protects both researchers and support staff.

---

### 4.3 Applied Practice & Innovation

AI can support efficiency and quality when used appropriately.

This domain enables RSOs to:

- support responsible use of AI for low-risk drafting or synthesis  
- distinguish between acceptable assistance and problematic substitution  
- adapt support practices as norms evolve  

Innovation is sustainable when advice is principle-led, not ad hoc.

---

### 4.4 Ethics, Equity & Impact

RSOs support equitable access to research opportunity.

AI capability includes:

- recognising how AI access and confidence vary across researchers  
- ensuring guidance does not disadvantage particular groups  
- considering reputational and ethical implications of AI-supported outputs  

Ethical support requires attention to systemic effects, not just individual cases.

---

### 4.5 Decision-Making & Governance

RSOs operate close to governance boundaries.

AI capability here involves:

- aligning advice with institutional policy and funder expectations  
- supporting documentation of AI-related decisions where relevant  
- knowing when to escalate issues to governance or ethics bodies  

Good governance protects credibility with funders and partners.

---

### 4.6 Reflection, Learning & Renewal

Research funding landscapes evolve rapidly.

Capability is strengthened when RSOs:

- track emerging funder positions on AI use  
- share learning internally and across institutions  
- update guidance iteratively rather than reactively  

This domain supports adaptability and professional confidence.

---

## 5. Practical actions for research support offices

The following actions strengthen AI capability in RSO contexts:

- **Make AI use discussable**  
  Encourage open conversation with researchers about AI assistance.

- **Clarify advisory scope**  
  Be explicit about what RSOs can advise on and where responsibility sits.

- **Align advice institutionally**  
  Ensure consistent messaging across teams and faculties.

- **Monitor funder signals**  
  Track evolving expectations and update guidance accordingly.

- **Document decision rationale**  
  Keep brief records of how AI considerations informed advice.

- **Share patterns, not incidents**  
  Feed emerging trends into institutional learning.

---

## 6. Signals of mature AI capability in research support

Research Support Offices with strong AI capability typically demonstrate:

- confident, consistent advisory practice  
- clarity about responsibility and boundaries  
- alignment with funder and institutional expectations  
- reduced escalation driven by uncertainty  
- trusted relationships with researchers  
- adaptive learning as norms change  

These signals reflect professional assurance maturity, not restriction.

---

## 7. How this brief fits within the AI Capability Framework

This brief applies the AI Capability Framework (2026 Edition) to research support and coordination roles.

To deepen this work, RSOs may explore:

- the full AI Capability Framework (PDF)  
- Practice Guides focused on research and governance  
- the Application Handbook for implementation pathways  
- cross-functional workshops with research leadership  

The Framework provides structure.  
Research Support Offices provide enablement, coherence, and trust.

---

## About CloudPedagogy

CloudPedagogy develops practical, ethical, and future-ready AI capability across education, research, and public service.

This brief is part of the **AI Capability Briefs** series, supporting role-specific judgement and decision-making using the CloudPedagogy AI Capability Framework (2026 Edition).

Learn more about the Framework:  
https://www.cloudpedagogy.com/pages/ai-capability-framework
